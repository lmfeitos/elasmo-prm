---
title: "random_forest"
author: "Leonardo Feitosa"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  cache = FALSE
)
library(tidyverse)
library(tidymodels)
library(here)
library(randomForest)
library(ranger)
library(googlesheets4)
library(naniar)
library(vip)
library(patchwork)
library(ggpmisc)

# Set data paths
basedir <- "G:/Meu Drive/PRM review/"
datadir <- file.path(basedir, "data/fish_base_data")
outdir <- file.path(basedir, "data/outputs") # calls present data from raster files

set.seed(42)
```

```{r}
prm_elasmo <- read_csv(here("data", "prm_elasmo_subset.csv"))

# sp counts per estimate type
avm_sp_count <- prm_elasmo %>%
  filter(estimate_type == "at-vessel mortality") %>%
  distinct(scientific_name) %>%
  count()

prm_sp_count <- prm_elasmo %>%
  filter(estimate_type == "post-release mortality") %>%
  distinct(scientific_name) %>%
  count()
```

```{r}
# create data subset with variables that will be used in the random forest model
prm_elasmo_subset <- prm_elasmo %>%
  select(
    scientific_name, gear_class, habitat_associated, estimate_type, estimate, sample_size,
    method, ventilation_method, max_size_cm, measure, median_depth, reproductive_mode, family
  ) %>%
  mutate(measure = case_when(
    scientific_name == "sharks" ~ "total_length",
    scientific_name %in% c("rays", "Dasyatis sp") ~ "disk_width",
    TRUE ~ measure
  )) %>%
  mutate(reproductive_mode = case_when(
    scientific_name == "sharks" ~ "yolk-sac viviparity",
    scientific_name == "rays" ~ "yolk-sac viviparity",
    TRUE ~ reproductive_mode
  )) %>%
  mutate_if(is.character, as.factor) %>% 
  filter(!grepl("sp", scientific_name))

# Create subset of the whole dataset with at-vessel mortality and calculate the weighted averages per species and gear
elasmo_trawl <- prm_elasmo_subset %>%
  filter(estimate_type == "at-vessel mortality" & estimate > 0) %>%
  filter(gear_class == "trawl") %>%
  mutate(est_count = sample_size * estimate) %>%
  group_by(scientific_name, gear_class) %>%
  mutate(mortality_prop = sum(est_count) / sum(sample_size)) %>%
  drop_na()

# Create subset of the whole dataset with post-release mortality and calculate the weighted averages per species and gear
elasmo_gillnet <- prm_elasmo_subset %>%
  filter(estimate_type == "at-vessel mortality" & estimate > 0) %>%
  filter(gear_class == "gillnet") %>%
  mutate(est_count = sample_size * estimate) %>%
  group_by(scientific_name, gear_class) %>%
  mutate(mortality_prop = sum(est_count) / sum(sample_size)) %>%
  drop_na()
```


```{r}
# split the data into training and test set

trawl_folds <- vfold_cv(elasmo_trawl, repeats = 5, v = 10)

gillnet_folds <- vfold_cv(elasmo_gillnet, repeats = 5, v = 10)
```


## Overview

This model aims to predict the likelihood of mortality per taxonomic family between sharks and rays using several species-specific bioecological features such as ventilation mode, median temperature, reproductive mode, median depth, as well as technological features such as the fishing gear each species was captured with.

```{r}
# Create the recipes for each estimate
trawl_recipe <- recipe(mortality_prop ~ median_depth + max_size_cm + reproductive_mode, data = elasmo_trawl) %>%
  step_normalize(all_numeric_predictors())

gillnet_recipe <- recipe(mortality_prop ~ median_depth + max_size_cm + ventilation_method, data = elasmo_gillnet) %>%
  step_normalize(all_numeric_predictors())
```

```{r}
# create models
trawl_rf <- rand_forest(trees = tune(), mtry = tune(), min_n = tune(), mode = "regression") %>%
  set_engine("ranger", verbose = TRUE, oob.error = TRUE, quantreg = TRUE, splitrule = "beta", importance = "impurity")

gillnet_rf <- rand_forest(trees = tune(), mtry = tune(), min_n = tune(), mode = "regression") %>%
  set_engine("ranger", verbose = TRUE, oob.error = TRUE, quantreg = TRUE, splitrule = "beta", importance = "impurity")
```

```{r}
# create workflows
trawl_wflw <- workflow() %>%
  add_model(trawl_rf) %>%
  add_recipe(trawl_recipe)

gillnet_wflw <- workflow() %>%
  add_model(gillnet_rf) %>%
  add_recipe(gillnet_recipe)
```

### Cross Validation

Cross validation will be used to choose the best hyperparameters for use in the model: 

* Number of trees
* Number of predictors in each sample
* Minimum data points in each node required for node split

```{r,include=FALSE}
# trawl_tune <- trawl_wflw %>% # use cross validation to tune parameters
#   tune_grid(
#     resamples = trawl_folds, # add cv folds
#     grid = 10
#   ) # use grid of parameters to test
```

```{r,include=FALSE}
# gillnet_tune <- gillnet_wflw %>% # use cross validation to tune parameters
#   tune_grid(
#     resamples = gillnet_folds, # add cv folds
#     grid = 10
#   ) # use grid of parameters to test
```

Below displays the results of cross validation tuning

```{r}
# autoplot(trawl_tune) + # plot results of tuning
#   theme_bw() # change theme
```

```{r}
# select_best(trawl_tune, metric = "rsq", n = 1) # get the best model
```

```{r, include=FALSE}
# trawl_final <- finalize_workflow(trawl_wflw, select_best(trawl_tune, metric = "rsq")) # finalize the workflow with the best model
# 
# saveRDS(trawl_final, here::here("data", "trawl_final.rds"))

trawl_final <- readRDS(here::here("data", "trawl_final.rds"))
```

```{r, include=FALSE}
trawl_fit <- fit(trawl_final, elasmo_trawl) # fit the data to the training data
```

```{r, include=FALSE}
trawl_train_predict <- predict(object = trawl_fit, new_data = elasmo_trawl) %>% # predict the training set
  bind_cols(elasmo_trawl) # bind training set column to prediction
```

```{r}
trawl_train_metrics <- trawl_train_predict %>%
  metrics(mortality_prop, .pred) # get testing data metrics
trawl_train_metrics
```

Below displays the results of cross validation tuning

```{r}
# autoplot(gillnet_tune) + # plot results of tuning
#   theme_bw() # change theme
```

```{r}
# select_best(gillnet_tune, metric = "rsq", n = 1) # get the best model
```

```{r, include=FALSE}
# gillnet_final <- finalize_workflow(gillnet_wflw, select_best(gillnet_tune, metric = "rsq")) # finalize the workflow with the best model
# 
# saveRDS(gillnet_final, here::here("data", "gillnet_final.rds"))

gillnet_final <- readRDS(here::here("data", "gillnet_final.rds"))
```

```{r, include=FALSE}
gillnet_fit <- fit(gillnet_final, elasmo_gillnet) # fit the data to the training data
```

```{r, include=FALSE}
gillnet_train_predict <- predict(object = gillnet_fit, new_data = elasmo_gillnet) %>% # predict the training set
  bind_cols(elasmo_gillnet) # bind training set column to prediction
```

```{r}
gill_train_metrics <- gillnet_train_predict %>%
  metrics(mortality_prop, .pred) # get testing data metrics
gill_train_metrics
```

```{r}
my_controls <- control_resamples(
  verbose = TRUE,
  save_pred = TRUE,
  extract = function(x) {
    model <- extract_fit_engine(x)
    model$prediction.error
  }
) # set to get prediction and out of bag errors

trawl_cv2 <- trawl_final %>%
  fit_resamples(trawl_folds, control = my_controls) # fit the folds to the final model

gillnet_cv2 <- gillnet_final %>%
  fit_resamples(gillnet_folds, control = my_controls) # fit the folds to the final model
```

```{r}
collect_metrics(trawl_cv2)

collect_metrics(gillnet_cv2)
```

## Quantile regression

```{r}
preds_bind <- function(data_fit, rf_fit) {
  predict(
    rf_fit$fit$fit$fit,
    workflows::extract_recipe(rf_fit) %>% bake(data_fit),
    type = "quantiles",
    quantiles = c(.05, .25, .5, .75, .95)
  ) %>%
    with(predictions) %>%
    as_tibble() %>%
    set_names(paste0(".pred", c("_05", "_25", "_50", "_75", "_95"))) %>%
    bind_cols(data_fit)
} # function to preform and extract quantile estimates from random forest

trawl_quant_test <- preds_bind(trawl_train_predict, trawl_fit) %>%
  mutate(
    range_50 = .pred_75 - .pred_25,
    range_95 = .pred_95 - .pred_05
  )

quant_in_50 <- trawl_quant_test %>%
  filter(!is.na(mortality_prop)) %>%
  mutate(in_interval = mortality_prop <= .pred_75 & mortality_prop >= .pred_25) %>%
  group_by(in_interval) %>%
  summarize(count = n())

percent_50 <- quant_in_50$count[2] / (quant_in_50$count[1] + quant_in_50$count[2]) * 100
percent_50

ggplot(trawl_quant_test) +
  geom_boxplot(aes(range_50)) +
  theme_bw()

write_csv(trawl_quant_test, here::here("data", "trawl_model_predictions.csv"))
```

```{r}
gillnet_quant_test <- preds_bind(gillnet_train_predict, gillnet_fit) %>%
  mutate(
    range_50 = .pred_75 - .pred_25,
    range_95 = .pred_95 - .pred_05
  )

quant_in_50 <- gillnet_quant_test %>%
  filter(!is.na(mortality_prop)) %>%
  mutate(in_interval = mortality_prop <= .pred_75 & mortality_prop >= .pred_25) %>%
  group_by(in_interval) %>%
  summarize(count = n())

percent_50 <- quant_in_50$count[2] / (quant_in_50$count[1] + quant_in_50$count[2]) * 100
percent_50

ggplot(gillnet_quant_test) +
  geom_boxplot(aes(range_50)) +
  theme_bw()

write_csv(gillnet_quant_test, here::here("data", "gillnet_model_predictions.csv"))
```

## trawl model - real values vs predicted values 

```{r}
p1 <- ggplot(trawl_quant_test, aes(x = mortality_prop, y = .pred_50)) + # plot ln of real versus ln of predicted
  geom_point() +
  stat_poly_line() +
  stat_poly_eq(use_label("eq")) +
  stat_poly_eq(label.y = 0.9) +
  theme_bw() +
  labs(
    x = "Observed At-Vessel Mortality Rate",
    y = "Predicted At-Vessel Mortality Rate"
  ) +
  theme(text = element_text(size = 10))
p1

summary(lm(.pred_50 ~ mortality_prop, data = trawl_quant_test))
```

## gillnet model - real values vs predicted values

```{r}
p2 <- ggplot(gillnet_train_predict, aes(x = mortality_prop, y = .pred)) + # plot ln of real versus ln of predicted
  geom_point() +
  stat_poly_line() +
  stat_poly_eq(use_label("eq")) +
  stat_poly_eq(label.y = 0.9) +
  theme_bw() +
  labs(
    x = "Observed Post Release Mortality Rate",
    y = "Predicted Post Release Mortality Rate"
  ) +
  theme(text = element_text(size = 10))
p2

summary(lm(.pred ~ mortality_prop, data = gillnet_train_predict))
```

### Variable importance for the at-vessel mortality and post-release mortality RF models
```{r}
v1 <- trawl_fit %>%
  extract_fit_parsnip() %>%
  vip() +
  theme_bw()
v1

v2 <- gillnet_fit %>%
  extract_fit_parsnip() %>%
  vip() +
  theme_bw()
v2
```

## Figures

Trawl

```{r}
plot1 <- p1 + v1 + plot_annotation(tag_levels = "A")

ggsave(plot1, file = paste0("trawl_val.pdf"), path = here::here("figs", "supp"), height = 10, width = 15)
```


Gillnet

```{r}
plot2 <- p2 + v2 + plot_annotation(tag_levels = "A")

ggsave(plot2, file = paste0("gill_val.pdf"), path = here::here("figs", "supp"), height = 10, width = 15)
```
